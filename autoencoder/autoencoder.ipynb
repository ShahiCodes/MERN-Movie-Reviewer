{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation with Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings file from kaggle*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movielens_data_file_url = (\n",
    "#     \"https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/download?datasetVersionNumber=7\"\n",
    "# )\n",
    "# movielens_zipped_file = keras.utils.get_file(\n",
    "#     \"archive\", movielens_data_file_url, extract=False\n",
    "# )\n",
    "# keras_datasets_path = Path(movielens_zipped_file)\n",
    "# movielens_dir = Path(movielens_zipped_file)\n",
    "# print(movielens_dir)\n",
    "# # Only extract the data the first time the script is run.\n",
    "# if not movielens_dir.exists():\n",
    "#     with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
    "#         # Extract files\n",
    "#         print(\"Extracting all the files now...\")\n",
    "#         zip.extractall(path=keras_datasets_path)\n",
    "#         print(\"Done!\")\n",
    "# ratings_file = movielens_dir / \"ratings_small.csv\"\n",
    "# df = pd.read_csv(ratings_file)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "# Use the ratings.csv file\n",
    "movielens_data_file_url = (\n",
    "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    ")\n",
    "movielens_zipped_file = keras.utils.get_file(\n",
    "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
    ")\n",
    "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
    "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
    "\n",
    "# Only extract the data the first time the script is run.\n",
    "if not movielens_dir.exists():\n",
    "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
    "        # Extract files\n",
    "        print(\"Extracting all the files now...\")\n",
    "        zip.extractall(path=keras_datasets_path)\n",
    "        print(\"Done!\")\n",
    "\n",
    "ratings_file = movielens_dir / \"ratings.csv\"\n",
    "df = pd.read_csv(ratings_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we do some preprocessing to encode users and movies as integer indices. We take the df columns userId and movieId, encode them, and save them into two new columns user and movie. min_rating and max_rating will be used to normalize the ratings later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "user_ids = df[\"userId\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "movie_ids = df[\"movieId\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then prepare the training and validation data by using \"user\", \"movie\", min_rating and max_rating. The data is split so that 90% of the data is used for training and 10% is used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "# Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, inside of a function showRecommendationsTJ(), we create a feature vector for one member of our team, Timothy Jan. We pick some movies, assign a rating to each of them, and create a new Dataframe. It is then used to generate 10 movie recommendations using the recommender model passed by the input model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRecommendationsTJ(model):\n",
    "  tj_movie_ID = [121231, 122900, 122902, 122904, 122906, 122912, 122916, 122918, 122920, 122922, 125916, 128360, 131739, 134130, 134853, 140715, 140956, 159858, 161354, 161594, 162082, 163645, 164367, 166024, 166528, 167370, 168248, 168252, 168366, 174053, 174055, 176101, 177285, 177593, 177763, 177765, 179401, 179819, 180031, 180985, 182715, 183635, 184471, 185029, 185135, 185585, 187031, 187593, 189713, 188189, ]\n",
    "  tj_movie_ratings = [2.5, 3.5, 2.5, 3.75, 4.25, 4.25, 4.25, 3.5, 3.75, 3.25, 1.5, 4, 3.75, 4, 3.5, 3.75, 4, 3.75, 3.75, 4.25, 4.5, 4.25, 4.5, 4, 3.75, 0.5, 4.25, 3.5, 2, 4, 2.5, 3, 3.25, 4, 4, 3.5, 3, 3, 4.25, 3, 4, 2, 2.5, 4.5, 4.25, 4, 2.5, 3.5, 3.5, 4.5, ]\n",
    "  tj_dict = {'movieId': tj_movie_ID, 'rating':tj_movie_ratings}\n",
    "  movies_watched_by_tj = pd.DataFrame(tj_dict)\n",
    "  movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
    "\n",
    "  movies_not_watched_by_tj = movie_df[\n",
    "      ~movie_df[\"movieId\"].isin(movies_watched_by_tj.movieId.values)\n",
    "  ][\"movieId\"]\n",
    "  movies_not_watched_by_tj = list(\n",
    "      set(movies_not_watched_by_tj).intersection(set(movie2movie_encoded.keys()))\n",
    "  )\n",
    "  movies_not_watched_by_tj = [[movie2movie_encoded.get(x)] for x in movies_not_watched_by_tj]\n",
    "  user_encoder = 609 #must be in range, does not affect prediction. tested\n",
    "  user_movie_array = np.hstack(\n",
    "      ([[user_encoder]] * len(movies_not_watched_by_tj), movies_not_watched_by_tj)\n",
    "  )\n",
    "  ratings = model.predict(user_movie_array).flatten()\n",
    "  top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "  recommended_movie_ids = [\n",
    "      movie_encoded2movie.get(movies_not_watched_by_tj[x][0]) for x in top_ratings_indices\n",
    "  ]\n",
    "  print(\"Showing recommendations for user: TJ\")\n",
    "  print(\"====\" * 9)\n",
    "  print(\"Movies with high ratings from user\")\n",
    "  print(\"----\" * 8)\n",
    "  top_movies_user = (\n",
    "      movies_watched_by_tj.sort_values(by=\"rating\", ascending=False)\n",
    "      .head(5)\n",
    "      .movieId.values\n",
    "  )\n",
    "  movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "  for row in movie_df_rows.itertuples():\n",
    "      print(row.title, \":\", row.genres)\n",
    "  print(\"----\" * 8)\n",
    "  print(\"Top 10 movie recommendations\")\n",
    "  print(\"----\" * 8)\n",
    "  recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "  for row in recommended_movies.itertuples():\n",
    "      print(row.title, \":\", row.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janti\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418/1418 [==============================] - 9s 6ms/step - loss: 0.6145 - val_loss: 0.6061\n",
      "Epoch 2/5\n",
      "1418/1418 [==============================] - 8s 6ms/step - loss: 0.5967 - val_loss: 0.6030\n",
      "Epoch 3/5\n",
      "1418/1418 [==============================] - 8s 6ms/step - loss: 0.5923 - val_loss: 0.6025\n",
      "Epoch 4/5\n",
      "1418/1418 [==============================] - 8s 6ms/step - loss: 0.5898 - val_loss: 0.6018\n",
      "Epoch 5/5\n",
      "1418/1418 [==============================] - 8s 6ms/step - loss: 0.5875 - val_loss: 0.6027\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding the embedded user-movie inputs.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class improvedRecommenderWithAutoEncoder(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(improvedRecommenderWithAutoEncoder, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "        self.user_movie_relationship1 = tf.keras.layers.Dense(50, activation= \"relu\")\n",
    "        #self.user_movie_relationship2 = tf.keras.layers.Dense(50, activation= \"relu\")\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation= \"sigmoid\", input_shape= (50,))\n",
    "\n",
    "        self.DenseSamplerZmean = tf.keras.layers.Dense(10, name=\"z_mean\")\n",
    "        self.DenseSamplerZlogvar = tf.keras.layers.Dense(10, name=\"z_log_var\")\n",
    "        self.Sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        \n",
    "        concat_inputs = tf.concat([user_vector, movie_vector], 1)\n",
    "        concat_bias = user_bias + movie_bias\n",
    "        \n",
    "        z_mean = self.DenseSamplerZmean(concat_inputs)\n",
    "        z_log_var = self.DenseSamplerZlogvar(concat_inputs)\n",
    "        response = self.Sampling([z_mean, z_log_var])\n",
    "\n",
    "        #response = self.user_movie_relationship1(concat_inputs)\n",
    "        response = self.user_movie_relationship1(response)\n",
    "        #response = self.user_movie_relationship2(response)\n",
    "        response = response + concat_bias\n",
    "        response = self.output_layer(response)\n",
    "        return response\n",
    "    \n",
    "\n",
    "final_model = improvedRecommenderWithAutoEncoder(num_users, num_movies, EMBEDDING_SIZE)\n",
    "final_model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
    ")\n",
    "\n",
    "history = final_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: TJ\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Kingsglaive: Final Fantasy XV (2016) : Action|Adventure|Animation|Drama|Fantasy|Sci-Fi\n",
      "Train to Busan (2016) : Action|Thriller\n",
      "The Girl with All the Gifts (2016) : Drama|Horror|Sci-Fi|Thriller\n",
      "A Quiet Place (2018) : Drama|Horror|Thriller\n",
      "Sorry to Bother You (2018) : Comedy|Fantasy|Sci-Fi\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Streetcar Named Desire, A (1951) : Drama\n",
      "Once Upon a Time in the West (C'era una volta il West) (1968) : Action|Drama|Western\n",
      "Amadeus (1984) : Drama\n",
      "Kolya (Kolja) (1996) : Comedy|Drama\n",
      "Trial, The (Procès, Le) (1962) : Drama\n",
      "Last Tango in Paris (Ultimo tango a Parigi) (1972) : Drama|Romance\n",
      "Jetée, La (1962) : Romance|Sci-Fi\n",
      "Bad Boy Bubby (1993) : Drama\n",
      "Memories of Murder (Salinui chueok) (2003) : Crime|Drama|Mystery|Thriller\n",
      "Band of Brothers (2001) : Action|Drama|War\n"
     ]
    }
   ],
   "source": [
    "showRecommendationsTJ(final_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "765c83fb16aa5d20abab0b27546b1fca432f83d7cf425231d5230579bbea4b90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
